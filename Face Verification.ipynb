{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rDhgS5alFMRq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Durga Yasasvi Y,   IMT2016060.\n",
    "# Srujan Swaroop G,  IMT2016033.\n",
    "# Siddharth Reddy D, IMT2016037.\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Flatten, Dropout, Activation\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import linalg as LA\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Flatten, Dropout, Activation\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "hCyJlriGmptU",
    "outputId": "b3e27b67-8030-45ba-c5e0-97f4ef377821"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# Load the Drive helper and mount\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ofOw-Joif5qK"
   },
   "outputs": [],
   "source": [
    "def train_split(l,train_percent):\n",
    "    random.seed(2019)\n",
    "    random.shuffle(l)\n",
    "    cut = int(len(l)*train_percent)\n",
    "    return l[:cut],l[cut:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2FHIiu0pen4k"
   },
   "outputs": [],
   "source": [
    "\n",
    "data_path =\"../content/drive/My Drive/AVR_data/\"\n",
    "folder_path = os.listdir(data_path)\n",
    "folder_path = [data_path+x for x in folder_path]\n",
    "train_imgs = []\n",
    "test_imgs = []\n",
    "count = 0\n",
    "train_labels = np.array([])\n",
    "test_labels = np.array([])\n",
    "a=0\n",
    "for path in folder_path:\n",
    "    image_names = os.listdir(path)\n",
    "    image_names = [path +\"/\"+x for x in image_names ]\n",
    "    a+=len(image_names)\n",
    "    tra,tes = train_split(image_names,1)\n",
    "    train_imgs=train_imgs + tra\n",
    "    test_imgs=test_imgs +tes\n",
    "    for i in tra:\n",
    "        train_labels = np.append(train_labels, count)\n",
    "    for i in tes:\n",
    "        test_labels = np.append(test_labels, count)\n",
    "    count= count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HBHgSqp8gEOK"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_images = []\n",
    "for i in train_imgs:\n",
    "    img = cv2.imread(i)\n",
    "    img = cv2.resize(img,(224,224),interpolation = cv2.INTER_CUBIC)\n",
    "    train_images.append(img)\n",
    "\n",
    "test_images = []    \n",
    "for i in test_imgs:\n",
    "    img = cv2.imread(i)\n",
    "    img = cv2.resize(img,(224,224),interpolation = cv2.INTER_CUBIC)\n",
    "    test_images.append(img)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lENNhGKGPr8w"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_images = [np.rollaxis(x, 2, 0) for x in train_images]\n",
    "test_images = [np.rollaxis(x, 2, 0) for x in test_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S2p7JaRRObcH"
   },
   "outputs": [],
   "source": [
    "all_image = train_images\n",
    "all_image_labels = train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P2qqkFRHaKuh"
   },
   "outputs": [],
   "source": [
    "def vgg_face(weights_path=None):\n",
    "    keras.backend.set_image_data_format('channels_first')\n",
    "    img = Input(shape=(3, 224, 224))\n",
    "\n",
    "    pad1_1 = ZeroPadding2D(padding=(1, 1))(img)\n",
    "    conv1_1 = Convolution2D(64, 3, 3, activation='relu', name='conv1_1')(pad1_1)\n",
    "    pad1_2 = ZeroPadding2D(padding=(1, 1))(conv1_1)\n",
    "    conv1_2 = Convolution2D(64, 3, 3, activation='relu', name='conv1_2')(pad1_2)\n",
    "    pool1 = MaxPooling2D((2, 2), strides=(2, 2),dim_ordering=\"th\")(conv1_2)\n",
    "\n",
    "    pad2_1 = ZeroPadding2D((1, 1))(pool1)\n",
    "    conv2_1 = Convolution2D(128, 3, 3, activation='relu', name='conv2_1')(pad2_1)\n",
    "    pad2_2 = ZeroPadding2D((1, 1))(conv2_1)\n",
    "    conv2_2 = Convolution2D(128, 3, 3, activation='relu', name='conv2_2')(pad2_2)\n",
    "    pool2 = MaxPooling2D((2, 2), strides=(2, 2),dim_ordering=\"th\")(conv2_2,)\n",
    "\n",
    "    pad3_1 = ZeroPadding2D((1, 1))(pool2)\n",
    "    conv3_1 = Convolution2D(256, 3, 3, activation='relu', name='conv3_1')(pad3_1)\n",
    "    pad3_2 = ZeroPadding2D((1, 1))(conv3_1)\n",
    "    conv3_2 = Convolution2D(256, 3, 3, activation='relu', name='conv3_2')(pad3_2)\n",
    "    pad3_3 = ZeroPadding2D((1, 1))(conv3_2)\n",
    "    conv3_3 = Convolution2D(256, 3, 3, activation='relu', name='conv3_3')(pad3_3)\n",
    "    pool3 = MaxPooling2D((2, 2), strides=(2, 2),dim_ordering=\"th\")(conv3_3)\n",
    "\n",
    "    pad4_1 = ZeroPadding2D((1, 1))(pool3)\n",
    "    conv4_1 = Convolution2D(512, 3, 3, activation='relu', name='conv4_1')(pad4_1)\n",
    "    pad4_2 = ZeroPadding2D((1, 1))(conv4_1)\n",
    "    conv4_2 = Convolution2D(512, 3, 3, activation='relu', name='conv4_2')(pad4_2)\n",
    "    pad4_3 = ZeroPadding2D((1, 1))(conv4_2)\n",
    "    conv4_3 = Convolution2D(512, 3, 3, activation='relu', name='conv4_3')(pad4_3)\n",
    "    pool4 = MaxPooling2D((2, 2), strides=(2, 2),dim_ordering=\"th\")(conv4_3)\n",
    "\n",
    "    pad5_1 = ZeroPadding2D((1, 1))(pool4)\n",
    "    conv5_1 = Convolution2D(512, 3, 3, activation='relu', name='conv5_1')(pad5_1)\n",
    "    pad5_2 = ZeroPadding2D((1, 1))(conv5_1)\n",
    "    conv5_2 = Convolution2D(512, 3, 3, activation='relu', name='conv5_2')(pad5_2)\n",
    "    pad5_3 = ZeroPadding2D((1, 1))(conv5_2)\n",
    "    conv5_3 = Convolution2D(512, 3, 3, activation='relu', name='conv5_3')(pad5_3)\n",
    "    pool5 = MaxPooling2D((2, 2), strides=(2, 2),dim_ordering=\"th\")(conv5_3)\n",
    "\n",
    "    fc6 = Convolution2D(4096, 7, strides= 7, activation='relu', name='fc6',data_format='channels_first')(pool5)\n",
    "    fc6_drop = Dropout(0.5)(fc6)\n",
    "    fc7 = Convolution2D(4096, 1, 1, activation='relu', name='fc7')(fc6_drop)\n",
    "    fc7_drop = Dropout(0.5)(fc7)\n",
    "    fc8 = Convolution2D(2622, 1, 1, name='fc8')(fc7_drop)\n",
    "    flat = Flatten()(fc8)\n",
    "    out = Activation('softmax')(flat)\n",
    "\n",
    "    model = Model(input=img, output=out)\n",
    "\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c6Yab2USaKxj"
   },
   "outputs": [],
   "source": [
    "model = vgg_face('../content/drive/My Drive/vgg-face-keras.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RSgkZlrN2r7m"
   },
   "outputs": [],
   "source": [
    "def getVec(Img):\n",
    "    Img = np.array(Img).astype(np.float32)\n",
    "    Img = np.expand_dims(Img, axis=0)\n",
    "    out = model.predict(Img)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EyFcl7z82vnO"
   },
   "outputs": [],
   "source": [
    "def Dist(vec1,vec2):\n",
    "  return np.linalg.norm(vec1-vec2)/(np.linalg.norm(vec1)*np.linalg.norm(vec2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "alnJCfR7aK3C"
   },
   "outputs": [],
   "source": [
    "data_path =\"../content/drive/My Drive/AVR_data/\"\n",
    "folder_path = os.listdir(data_path)\n",
    "folder_path = [data_path+x for x in folder_path]\n",
    "train_imgs = []\n",
    "test_imgs = []\n",
    "count = 0\n",
    "train_labels = np.array([])\n",
    "test_labels = np.array([])\n",
    "a=0\n",
    "dis = []\n",
    "for path in folder_path:\n",
    "    image_names = os.listdir(path)\n",
    "    image_names = [path +\"/\"+x for x in image_names ]\n",
    "#     print(image_names)\n",
    "    for i in range(0,len(image_names)):\n",
    "      for j in range(i,len(image_names)):\n",
    "\n",
    "        img1 = cv2.imread(image_names[i])\n",
    "        img2 = cv2.imread(image_names[j])\n",
    "      \n",
    "        img1 = cv2.resize(img1,(224,224),interpolation = cv2.INTER_CUBIC)\n",
    "        img2 = cv2.resize(img2,(224,224),interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "        img1 = np.rollaxis(img1, 2, 0)\n",
    "        img2 = np.rollaxis(img2, 2, 0)\n",
    "      \n",
    "        dis.append(Dist(img1,img2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DkkDDudfSoDl"
   },
   "outputs": [],
   "source": [
    "data_path =\"./../content/drive/My Drive/AVR_data/\"\n",
    "folder_path = os.listdir(data_path)\n",
    "folder_path = [data_path+x for x in folder_path]\n",
    "train_imgs = []\n",
    "test_imgs = []\n",
    "count = 0\n",
    "train_labels = np.array([])\n",
    "test_labels = np.array([])\n",
    "a=0\n",
    "random_dis = []\n",
    "\n",
    "for i in range(0,9500):\n",
    "  path1 = random.choice(folder_path)\n",
    "  path2 = random.choice(folder_path)\n",
    "  \n",
    "  \n",
    "  image_names1 = os.listdir(path1)\n",
    "  image_names1 = [path1 +\"/\"+x for x in image_names1 ]\n",
    "\n",
    "  image_names2 = os.listdir(path2)\n",
    "  image_names2 = [path2 +\"/\"+x for x in image_names2 ]\n",
    "\n",
    "  final_image1 = random.choice(image_names1)\n",
    "  final_image2 = random.choice(image_names2)\n",
    "  \n",
    "  img1 = cv2.imread(final_image1)\n",
    "  img2 = cv2.imread(final_image2)\n",
    "\n",
    "      \n",
    "  img1 = cv2.resize(img1,(224,224),interpolation = cv2.INTER_CUBIC)\n",
    "  img2 = cv2.resize(img2,(224,224),interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "  img1 = np.rollaxis(img1, 2, 0)\n",
    "  img2 = np.rollaxis(img2, 2, 0)\n",
    "      \n",
    "  if(path1==path2):\n",
    "    i = i-1  \n",
    "  else:\n",
    "    random_dis.append(Dist(img1,img2))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gu1-k1EVfEr3"
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "for i in dis:\n",
    "  X.append(i)\n",
    "for i in random_dis:\n",
    "  X.append(i)\n",
    "y = []\n",
    "for i in dis:\n",
    "  y.append(1)\n",
    "for i in random_dis:\n",
    "  y.append(0)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WMQmmJpJbNeg"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0mtfF4b3iE5s"
   },
   "outputs": [],
   "source": [
    "X_train = np.array(X_train).reshape((len(X_train),1))\n",
    "X_test = np.array(X_test).reshape((len(X_test),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R_SjHMHJiZhS"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC # \"Support Vector Classifier\" \n",
    "clf = SVC(kernel='linear') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "-n006pGE-e0L",
    "outputId": "c65d951e-4b82-4fea-887e-795a734b2fa7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 106,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "csuunqx_-smb"
   },
   "outputs": [],
   "source": [
    " accuracy = clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "LJQAcYM9-38K",
    "outputId": "4d298e43-2b5b-4c2f-f6e8-aec2142f8a19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuuracy Score:  82.16870342771982 %\n"
     ]
    }
   ],
   "source": [
    "print('Acuuracy Score: ', accuracy * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W3LlbMn-FCLX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Face_verification.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
